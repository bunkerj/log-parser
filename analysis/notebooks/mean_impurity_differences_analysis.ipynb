{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('../../')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.graphics.api as smg\n",
    "from warnings import filterwarnings\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso, LinearRegression\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from graphs.utils import plot_morris_method_graph\n",
    "from analysis.utils import get_sa_problem\n",
    "from SALib.sample.morris import sample\n",
    "from SALib.analyze.morris import analyze\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n",
    "\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = ShuffleSplit(100)\n",
    "SCORING = 'neg_mean_squared_error'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PROPERTIES_PATH = r'..\\..\\results\\dataset_properties.csv'\n",
    "IMPURITY_DIFF_PATH = r'..\\..\\results\\impurity_differences.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_properties_df = pd.read_csv(DATASET_PROPERTIES_PATH)\n",
    "dataset_properties_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impurity_differences_df = pd.read_csv(IMPURITY_DIFF_PATH)\n",
    "impurity_differences_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = impurity_differences_df.merge(dataset_properties_df, on='name')\n",
    "data_df = data_df.sample(frac=1)\n",
    "\n",
    "data_df['impurity_mean_diff'] = data_df['avg_lab_impurity'] - data_df['avg_unlab_impurity']\n",
    "data_df['impurity_var_sum'] = data_df['var_lab_impurity'] + data_df['var_unlab_impurity']\n",
    "\n",
    "X_df = data_df.drop(['name', 'impurity_mean_diff', 'impurity_var_sum', \n",
    "                     'avg_lab_impurity', 'avg_unlab_impurity', \n",
    "                     'var_lab_impurity', 'var_unlab_impurity'], axis=1)\n",
    "\n",
    "y_df = data_df[['impurity_mean_diff']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_scores_df = dataset_properties_df[['silhouette_score', 'calinski_harabasz_score', 'davies_bouldin_score']]\n",
    "corr_scores_df['custom_score'] = (dataset_properties_df['inter_cluster_spread'] \n",
    "                                  / dataset_properties_df['intra_cluster_spread']).reset_index(drop=True)\n",
    "corr_scores_df = corr_scores_df[corr_scores_df['custom_score'] != np.inf]\n",
    "\n",
    "corr_scores_matrix = np.corrcoef(corr_scores_df.T)\n",
    "smg.plot_corr(corr_scores_matrix, corr_scores_df.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = pd.concat([X_df, y_df], axis=1).reset_index(drop=True)\n",
    "corr_matrix_base = np.corrcoef(corr_df.T)\n",
    "smg.plot_corr(corr_matrix_base, corr_df.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': range(1, 20),\n",
    "    'max_features': range(1, X_df.shape[1] + 1),\n",
    "}\n",
    "random_forest_gs = GridSearchCV(RandomForestRegressor(), \n",
    "                                param_grid=param_grid, scoring=SCORING,\n",
    "                                cv=CV, verbose=True, n_jobs=-1)\n",
    "\n",
    "random_forest_gs.fit(X_df, y_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': range(1, 20),\n",
    "    'num_round': range(5, 100, 5),\n",
    "}\n",
    "\n",
    "boosted_trees_gs = GridSearchCV(xgb.XGBRegressor(), \n",
    "                      param_grid=param_grid, scoring=SCORING,\n",
    "                      cv=CV, verbose=True, n_jobs=-1)\n",
    "\n",
    "boosted_trees_gs.fit(X_df, y_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = get_sa_problem(X_df)\n",
    "inputs = sample(problem, 1000, num_levels=4)\n",
    "\n",
    "X_morris_df = pd.DataFrame(inputs, columns=X_df.columns)\n",
    "results = boosted_trees_gs.predict(X_morris_df)\n",
    "\n",
    "sensitivity_indices = \\\n",
    "    analyze(problem,\n",
    "            inputs,\n",
    "            results,\n",
    "            conf_level=0.95,\n",
    "            num_levels=5)\n",
    "\n",
    "plot_morris_method_graph(sensitivity_indices, 'Impurity Differences')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), Lasso())\n",
    "\n",
    "param_grid = {'lasso__alpha': np.logspace(-4, 2, 100)}\n",
    "lasso_gs = GridSearchCV(pipe, \n",
    "                        param_grid=param_grid, scoring=SCORING,\n",
    "                        cv=CV, verbose=True, n_jobs=-1)\n",
    "\n",
    "lasso_gs.fit(X_df, y_df)\n",
    "lasso_gs.score(X_df, y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'coef_names': X_df.columns,\n",
    "    'coef_values': lasso_gs.best_estimator_['lasso'].coef_,\n",
    "}\n",
    "\n",
    "coef_df = pd.DataFrame(data)\n",
    "coef_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_linear_df = X_df[['provided_labels_count', 'token_count_avg_entropy_a1']].assign(intercept=1)\n",
    "X_linear_df['token_count_avg_entropy_a1^2'] = X_df['token_count_avg_entropy_a1'] ** 2\n",
    "X_linear_df['provided_labels_count*token_count_avg_entropy_a1'] = \\\n",
    "    X_df['provided_labels_count'] * X_df['token_count_avg_entropy_a1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols = sm.OLS(y_df, X_linear_df)\n",
    "results = ols.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "boosted_trees_gs_scores = cross_val_score(boosted_trees_gs.best_estimator_, \n",
    "                                          X_df, y_df, cv=CV, \n",
    "                                          scoring=SCORING, n_jobs=-1)\n",
    "random_forest_gs_scores = cross_val_score(random_forest_gs.best_estimator_, \n",
    "                                          X_df, y_df, cv=CV, \n",
    "                                          scoring=SCORING, n_jobs=-1)\n",
    "lin_reg_scores = cross_val_score(LinearRegression(), \n",
    "                                 X_linear_df, y_df, cv=CV, \n",
    "                                 scoring=SCORING, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Boosted Trees CV NMSE: {:16.6f} (±{:.6f})'.format(boosted_trees_gs_scores.mean(), boosted_trees_gs_scores.std() * 2))\n",
    "print('Random Forest CV NMSE: {:16.6f} (±{:.6f})'.format(random_forest_gs_scores.mean(), random_forest_gs_scores.std() * 2))\n",
    "print('Linear Regression CV NMSE: {:12.6f} (±{:.6f})'.format(lin_reg_scores.mean(), lin_reg_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosted_trees_gs_total_r2 = boosted_trees_gs.best_estimator_.fit(X_df, y_df).score(X_df, y_df)\n",
    "random_forest_gs_total_r2 = random_forest_gs.best_estimator_.fit(X_df, y_df).score(X_df, y_df)\n",
    "lin_reg_total_r2 = LinearRegression().fit(X_linear_df, y_df).score(X_linear_df, y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Boosted Trees Total R^2: {:13.6f}'.format(boosted_trees_gs_total_r2))\n",
    "print('Random Forest Total R^2: {:13.6f}'.format(random_forest_gs_total_r2))\n",
    "print('Linear Regression Total R^2: {:9.6f}'.format(lin_reg_total_r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_linear_vif_df = X_linear_df[['provided_labels_count', 'token_count_avg_entropy_a1']]\n",
    "p = X_linear_vif_df.shape[1]\n",
    "vif_df = pd.DataFrame()\n",
    "vif_df['VIF Factor'] = [vif(X_linear_vif_df.values, i) for i in range(p)]\n",
    "vif_df['features'] = X_linear_vif_df.columns\n",
    "vif_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.qqplot(results.resid, line='s')\n",
    "plt.grid()\n",
    "plt.plot()\n",
    "_, p = stats.shapiro(results.resid)\n",
    "print('Shapiro-Wilk test p-value: {}'.format(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.resid\n",
    "plt.scatter(y_df, results.resid)\n",
    "plt.xlabel('Response')\n",
    "plt.ylabel('Residual')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
